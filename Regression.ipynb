{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regression.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7Tu7jyEX0XsyMcrgEQgcM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugatha1/Regression/blob/main/Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression model on trainig set"
      ],
      "metadata": {
        "id": "kdDJSiYZyT8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "R015LOwPydYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predicting the test set results"
      ],
      "metadata": {
        "id": "GefBF569zFU9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = regressor.predict(X_test)"
      ],
      "metadata": {
        "id": "1fQDiPW5zKu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualising the training test results "
      ],
      "metadata": {
        "id": "DdtNOeIQzwRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X_trainl, y_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train), color='blue')\n",
        "plt.title('...')\n",
        "plt.xlabel('...')\n",
        "plt.ylabel('...')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_s7QX8nHz5B-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple linear regression model on training set"
      ],
      "metadata": {
        "id": "2zxSAjZCEvhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "gDtC55ftFWcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial regression model"
      ],
      "metadata": {
        "id": "4XlWqjrxMTrm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly_reg = PolynomialFeatures(degree = 2)\n",
        "X_poly = poly_reg.fit_transform(X)\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_poly, y) "
      ],
      "metadata": {
        "id": "Z-MxNYFtMaDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualise the polynomial regression results"
      ],
      "metadata": {
        "id": "rjhkHsvmN4bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X, y, color = 'red')\n",
        "plt.plot(X, lin_reg.predict(poly_reg.fit_transform(X)), color = 'blue')\n",
        "plt.title('...')\n",
        "plt.xlabel('...')\n",
        "plt.ylabel('...')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CdSigfDGN-lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support vector regression\n",
        "  we have support vector linear regression and support vector nonlinear regression"
      ],
      "metadata": {
        "id": "SO_i7NRXk195"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVR model on the whole dataset\n",
        "\n",
        "from sklearn.svm import SVR\n",
        "regressor = SVR(kernel = 'rbf')\n",
        "regressor.fit(X, y)"
      ],
      "metadata": {
        "id": "L4tQj3fCk8VY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decision Trees\n",
        " Classification Trees and Regression Trees"
      ],
      "metadata": {
        "id": "-pn06xuhunjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the decision tree regression model on whole dataset\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "regressor = DecisionTreeRegressor(random_state=0)\n",
        "regressor.fit(X, y)"
      ],
      "metadata": {
        "id": "Vw7mI7gK4mB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "\n",
        "It is a version of ensemble learning. Ensemble learning means we are taking same alogirthm muliple times and put them together to make it powerful than original one. \n",
        "\n",
        "step1 :  Pick at random K data points from the training set.                    \n",
        "step2 : Build the decision tree associated to these K data points.              \n",
        "step3 : Chooes the number Ntree of trees you want to build and repeat STEPS 1&2\n",
        "step4 : For a new data point, make each one of your Ntree trees predict the value of Y to fot the data point in question, and assign the new data point the average across all of the predicted Y values "
      ],
      "metadata": {
        "id": "O_6xj7Sw5c5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the random forest regression model on the whole dataset\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators=10, random_state=0)\n",
        "regressor.fit(X, y)"
      ],
      "metadata": {
        "id": "Gzo-T9h0FXXe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}